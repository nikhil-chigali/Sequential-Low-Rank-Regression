{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n",
      "(1000, 50)\n",
      "(100, 50)\n"
     ]
    }
   ],
   "source": [
    "d = 100 # Number of features\n",
    "m = 50 # Output dimension\n",
    "n = 1000  # Number of samples\n",
    "rank = 10  # Rank of the matrix W\n",
    "n_agents = 3 # Number of agents\n",
    "\n",
    "# Generating n input data points with d features with a normal distribution\n",
    "X = np.random.randn(n, d)\n",
    "\n",
    "# Normalizing the rows of X\n",
    "X = X / la.norm(X, axis=1, keepdims=True)\n",
    "\n",
    "# Generating a random matrix W with rank r\n",
    "e = 1\n",
    "S_star = [1]\n",
    "\n",
    "# Generating the eigenvalues of W\n",
    "eigen_gaps = [10 for i in range(rank-1)]\n",
    "\n",
    "for i in range(rank-1):\n",
    "    e = e + eigen_gaps[i]\n",
    "    S_star.insert(0,e)\n",
    "\n",
    "M = np.random.randn(d, m)\n",
    "[U, _, V] = la.svd(M, full_matrices=False)\n",
    "\n",
    "A_star = U[:, :rank] @ np.diag(np.sqrt(S_star))\n",
    "B_star = np.diag(np.sqrt(S_star)) @ V[:rank, :]\n",
    "\n",
    "W_star = A_star @ B_star\n",
    "\n",
    "# Generating the output data Y\n",
    "Y_star = X @ W_star\n",
    "\n",
    "# Adding noise to the output data\n",
    "Y = Y_star + 0.1 * np.random.randn(n, m)\n",
    "\n",
    "# Splitting the data into n_agents parts\n",
    "X_split = np.array_split(X, n_agents)\n",
    "Y_split = np.array_split(Y, n_agents)\n",
    "\n",
    "# Saving the data\n",
    "np.save('data/X.npy', X)\n",
    "np.save('data/Y.npy', Y)\n",
    "np.save('data/W_star.npy', W_star)\n",
    "np.save('data/A_star.npy', A_star)\n",
    "np.save('data/B_star.npy', B_star)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(W_star.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring similarities and subspace overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True loss:  251.5761037285171\n"
     ]
    }
   ],
   "source": [
    "class RegressionAgent:\n",
    "    def __init__(self, d, m):\n",
    "        self.d = d\n",
    "        self.m = m\n",
    "        self.W = None\n",
    "    \n",
    "    def init_weights(self, W=None):\n",
    "        if W is None:\n",
    "            self.W = np.random.randn(self.d, self.m)\n",
    "        else:\n",
    "            self.W = W\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X @ self.W\n",
    "    \n",
    "    def loss(self, X, Y):\n",
    "        return 0.5 * la.norm(Y - self.forward(X))**2\n",
    "    \n",
    "    def update_weights(self, X, Y, lr=0.01):\n",
    "        self.W = self.W - lr * (X.T @ (X @ self.W - Y))\n",
    "    \n",
    "# True model for reference\n",
    "true_agent = RegressionAgent(d, m)\n",
    "true_agent.init_weights(W_star)\n",
    "\n",
    "print(\"True loss: \", true_agent.loss(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0: Initial loss on the whole dataset: 172312.10713647128\n",
      "Agent 1: Initial loss on the whole dataset: 170330.52680617437\n",
      "Agent 2: Initial loss on the whole dataset: 170806.12222502741\n"
     ]
    }
   ],
   "source": [
    "agents = [RegressionAgent(d, m) for i in range(n_agents)]\n",
    "\n",
    "# W_init = np.random.randn(d, m)\n",
    "\n",
    "for i in range(n_agents):\n",
    "    # agents[i].init_weights(W_init)\n",
    "    agents[i].init_weights()\n",
    "\n",
    "print(\"Agent 0: Initial loss on the whole dataset:\", agents[0].loss(X, Y))\n",
    "print(\"Agent 1: Initial loss on the whole dataset:\", agents[1].loss(X, Y))\n",
    "print(\"Agent 2: Initial loss on the whole dataset:\", agents[2].loss(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent\n",
      "Epoch 100: 565.1210336897396\n",
      "Epoch 200: 103.66253397299697\n",
      "Epoch 300: 65.88431048197418\n",
      "Epoch 400: 61.10528192652962\n",
      "Epoch 500: 60.38467031863687\n",
      "Epoch 600: 60.264809127330274\n",
      "Epoch 700: 60.24347986708611\n",
      "Epoch 800: 60.239484464540226\n",
      "Epoch 900: 60.23870531493153\n",
      "Epoch 1000: 60.23854849519536\n",
      "Training agent\n",
      "Epoch 100: 582.9260835482628\n",
      "Epoch 200: 102.26463447809303\n",
      "Epoch 300: 64.08921123939476\n",
      "Epoch 400: 59.301600369290846\n",
      "Epoch 500: 58.56253472064687\n",
      "Epoch 600: 58.43404066784907\n",
      "Epoch 700: 58.410016640395874\n",
      "Epoch 800: 58.405315410930704\n",
      "Epoch 900: 58.40436791501842\n",
      "Epoch 1000: 58.404173141462735\n",
      "Training agent\n",
      "Epoch 100: 598.4137589651317\n",
      "Epoch 200: 106.04108900338254\n",
      "Epoch 300: 64.58404724249752\n",
      "Epoch 400: 59.43959196534426\n",
      "Epoch 500: 58.691465103037935\n",
      "Epoch 600: 58.572735946489225\n",
      "Epoch 700: 58.55277942609558\n",
      "Epoch 800: 58.5492813834573\n",
      "Epoch 900: 58.54864791908056\n",
      "Epoch 1000: 58.54853014671986\n"
     ]
    }
   ],
   "source": [
    "def train_W(agent, X, Y, lr=0.001, epochs=100):\n",
    "    loss = []\n",
    "    print(\"Training agent\")\n",
    "    for i in range(1, epochs + 1):\n",
    "        agent.update_weights(X, Y, lr)\n",
    "        loss.append(agent.loss(X, Y))\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch {i}: {loss[-1]}\")\n",
    "    return loss\n",
    "\n",
    "\n",
    "losses = [\n",
    "    train_W(agents[i], X_split[i], Y_split[i], 1e-2, 1000) \n",
    "    for i in range(n_agents)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0: Loss on the whole dataset: 297.67939923535107\n",
      "Agent 1: Loss on the whole dataset: 297.7461632624849\n",
      "Agent 2: Loss on the whole dataset: 299.78394180214644\n"
     ]
    }
   ],
   "source": [
    "print(\"Agent 0: Loss on the whole dataset:\", agents[0].loss(X, Y))\n",
    "print(\"Agent 1: Loss on the whole dataset:\", agents[1].loss(X, Y))\n",
    "print(\"Agent 2: Loss on the whole dataset:\", agents[2].loss(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model aggregation loss:  234.20915733911215\n"
     ]
    }
   ],
   "source": [
    "def federated_average_W(agents):\n",
    "    W = np.zeros((d, m))\n",
    "    for agent in agents:\n",
    "        W += agent.W\n",
    "    W /= len(agents)\n",
    "    return W\n",
    "\n",
    "W_avg = federated_average_W(agents)\n",
    "model_agg = RegressionAgent(d, m)\n",
    "model_agg.init_weights(W_avg)\n",
    "\n",
    "print(\"Model aggregation loss: \", model_agg.loss(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50)\n",
      "(100, 50)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "Distance between true model and model aggregation:  9.999999999999998\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def subspace_overlap(W1, W2):\n",
    "    U1, _, _ = la.svd(W1)\n",
    "    U2, _, _ = la.svd(W2)\n",
    "    return la.norm(U1.T @ U2, ord='fro')**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
